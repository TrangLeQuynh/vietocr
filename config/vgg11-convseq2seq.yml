# change to list chars of your dataset or use default vietnamese chars
vocab: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 `\|":./%;-~!@#$^&?<>*()_+={}[],'

weights: weights/vgg11_convseq2seq.pth

device: cpu

backbone: vgg11_bn
cnn:
    # pooling stride size
    ss:
        - [2, 2]
        - [2, 2]
        - [2, 1]
        - [2, 1]
        - [1, 1]         
    # pooling kernel size 
    ks:
        - [2, 2]
        - [2, 2]
        - [2, 1]
        - [2, 1]
        - [1, 1]
    # dim of ouput feature map
    hidden: 256

seq_modeling: convseq2seq
transformer:
    emb_dim: 256
    hid_dim: 512
    enc_layers: 10
    dec_layers: 10
    enc_kernel_size: 3
    dec_kernel_size: 3
    dropout: 0.1
    pad_idx: 0
    device: cpu
    enc_max_length: 512
    dec_max_length: 512

optimizer:
    max_lr: 0.001
    pct_start: 0.1    
    
trainer:
    batch_size: 32
    print_every: 200
    valid_every: 4000
    iters: 100000
    # where to save our model for predi_ction
    export: ./weights/vgg11_convseq2seq.pth
    checkpoint: ./checkpoint/vgg11_convseq2seq.pth
    log: ./train.log
    # null to disable compuate accuracy, or change to number of sample to enable validiation while training
    metrics: null

dataset:    
    # name of your dataset
    name: data
    # path to annotation and image
    data_root: ../../Data_synth/vietocr_data/
    train_annotation: train_line_annotation.txt
    valid_annotation: val_line_annotation.txt
    # resize image to 32 height, larger height will increase accuracy
    image_height: 32
    image_min_width: 32
    image_max_width: 512

dataloader:
    num_workers: 3
    pin_memory: True

aug:
    image_aug: true
    masked_language_model: true

predictor:
    # disable or enable beamsearch while prediction, use beamsearch will be slower
    beamsearch: False

quiet: False 
